import torch

import matplotlib.pyplot as plt
import imageio
import argparse
import os

from diffusion_core.model import DiffusionModel
from diffusion_core.schedule import get_cosine_schedule
from diffusion_core.sampling import ddpm_sample, ddim_sample

device = "mps" if torch.backends.mps.is_available() else "cpu"

def save_gif(frames, path):
    # Normalize and convert frames to uint8
    processed_frames = []
    for f in frames:
        f = (f.clamp(-1, 1) + 1) / 2
        f = (f * 255).type(torch.uint8).cpu().squeeze().numpy()
        processed_frames.append(f)

    imageio.mimsave(path, processed_frames, duration=0.1, loop=0)
    print(f"Saved GIF to {path}")

def run_test(args):

    if not os.path.exists(args.model_path):
        raise RuntimeError("Model not found!")
    
    checkpoint = torch.load(args.model_path, map_location=device)

    # Extract config from conf
    if "config" in checkpoint:
        config = checkpoint["config"]
        model_cfg = config["model"]
        sample_cfg = config["sample"]
        print(f"Loaded configuration for experiment: {config.get('experiment_name', 'Unknown')}")
    else:
        print("Warning: No config found in checkpoint. Using default fallback.")
        model_cfg = {"image_size": 32, "bottleneck_dim": 4, "in_channels": 1,
                     "out_dim": 1, "num_classes": 10, "model_channels": 64
                    }
        sample_cfg = {"T": 1000, "ddim_steps": 50}

    # Load model
    model = DiffusionModel(
                image_size=model_cfg["image_size"],
                in_channels=model_cfg["in_channels"],
                model_channels=model_cfg["model_channels"],
                bottleneck_dim=model_cfg["bottleneck_dim"],
                out_dim = model_cfg["out_dim"],
                num_classes=model_cfg["num_classes"]
                ).to(device)

    model.load_state_dict(checkpoint["ema_model_state_dict"])
    model.eval()

    # Setup schedule
    T = sample_cfg["T"]
    betas = get_cosine_schedule(T).to(device)
    alphas = 1.0 - betas
    alphas_cumprod = torch.cumprod(alphas.cpu(), axis=0).to(device)

    # Condition
    if args.digit is not None:
        y = torch.tensor([args.digit]).long().to(device)
        print(f"Generating digit: {args.digit}")
    else:
        y = torch.randint(0, 10, (1,)).long().to(device)
        print(f"Generating random digit: {y.item()}")

    # Sampling
    intermediate_steps = []
    
    if args.sampling == "ddim":
        sampler = ddim_sample(model,
                              n_samples=1,
                              image_size=model_cfg["image_size"],
                              in_channels=model_cfg["in_channels"],
                              alphas_cumprod=alphas_cumprod,
                              y=y,
                              device=device,
                              ddim_steps=sample_cfg["ddim_steps"],
                              seed=args.seed
                              )
    else:
        sampler = ddpm_sample(model,
                              n_samples=1,
                              image_size=model_cfg["image_size"],
                              in_channels=model_cfg["in_channels"],
                              betas=betas,
                              alphas=alphas,
                              alphas_cumprod=alphas_cumprod,
                              y=y,
                              device=device,
                              seed=args.seed
                              )
        
    # Collet intermediate steps
    for i, (x, _) in enumerate(sampler):
        if args.sampling == "ddim" or i % 20 == 0:
            intermediate_steps.append(x)

    # Capture final result as well
    if len(intermediate_steps) == 0 or intermediate_steps[-1] is not x:
        intermediate_steps.append(x)

    # Save
    save_gif(intermediate_steps, "result.gif")
    final_img = (intermediate_steps[-1].clamp(-1, 1) + 1) / 2
    plt.imsave("result.png", final_img.cpu().squeeze(), cmap="gray")
    print("Done.")

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--model_path", type=str, default="checkpoints/diffusion_model_final.pth")
    parser.add_argument("--digit", type=int, default=None, help="Specific digit to be generated by the diffusion model")
    parser.add_argument("--sampling", type=str, default="ddim", choices=["ddpm", "ddim"])
    parser.add_argument("--seed", type=int, default=None)
    args = parser.parse_args()

    run_test(args)