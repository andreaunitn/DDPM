import torch

import matplotlib.pyplot as plt
import imageio
import argparse
import os

from diffusion_core.model import DiffusionModel
from diffusion_core.schedule import get_cosine_schedule
from diffusion_core.sampling import ddpm_sample, ddim_sample

device = "mps" if torch.backends.mps.is_available() else "cpu"

def save_gif(frames, path):
    # Normalize and convert frames to uint8
    processed_frames = []
    for f in frames:
        f = (f.clamp(-1, 1) + 1) / 2
        f = (f * 255).type(torch.uint8).cpu().squeeze().numpy()
        processed_frames.append(f)

    imageio.mimsave(path, processed_frames, duration=0.1, loop=0)
    print(f"Saved GIF to {path}")

def run_test(args):
    # Load model
    model = DiffusionModel(
                image_size=32,
                bottleneck_dim=4,
                in_channels=1,
                out_dim=1,
                num_classes=10
                ).to(device)
    
    if os.path.exists(args.model_path):
        checkpoint = torch.load(args.model_path, map_location=device)
        model.load_state_dict(checkpoint["ema_model_state_dict"])
        model.eval()
    else:
        raise RuntimeError("Model not found!")

    # Setup schedule
    T = 1000
    betas = get_cosine_schedule(T).to(device)
    alphas = 1.0 - betas
    alphas_cumprod = torch.cumprod(alphas.cpu(), axis=0).to(device)

    # Condition
    if args.digit is not None:
        y = torch.tensor([args.digit]).long().to(device)
        print(f"Generating digit: {args.digit}")
    else:
        y = torch.randint(0, 10, (1,)).long().to(device)
        print(f"Generating random digit: {y.item()}")

    # Sampling
    intermediate_steps = []
    
    if args.sampling == "ddim":
        sampler = ddim_sample(model,
                              1,
                              32,
                              1,
                              alphas_cumprod,
                              y,
                              device,
                              ddim_steps=args.steps,
                              seed=args.seed
                              )
    else:
        sampler = ddpm_sample(model,
                              1,
                              32,
                              1,
                              betas,
                              alphas,
                              alphas_cumprod,
                              y,
                              device,
                              seed=args.seed
                              )
        
    # Collet intermediate steps
    for i, (x, _) in enumerate(sampler):
        if args.sampling == "ddim" or i % 20 == 0:
            intermediate_steps.append(x)

    # Capture final result as well
    if len(intermediate_steps) == 0 or intermediate_steps[-1] is not x:
        intermediate_steps.append(x)

    # Save
    save_gif(intermediate_steps, "result.gif")
    final_img = (intermediate_steps[-1].clamp(-1, 1) + 1) / 2
    plt.imsave("result.png", final_img.cpu().squeeze(), cmap="gray")
    print("Done.")

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--model_path", type=str, default="checkpoints/diffusion_model_final.pth")
    parser.add_argument("--digit", type=int, default=None, help="Specific digit to be generated by the diffusion model")
    parser.add_argument("--sampling", type=str, default="ddim", choices=["ddpm", "ddim"])
    parser.add_argument("--steps", type=int, default=50, help="Steps for DDIM")
    parser.add_argument("--seed", type=int, default=None)
    args = parser.parse_args()

    run_test(args)